##  Azure Data Pipeline â€“ AdventureWorks Project

Ce projet met en Å“uvre une pipeline de traitement de donnÃ©es sur Azure pour transformer les donnÃ©es de la base **AdventureWorksLT** et les visualiser dans un **dashboard Power BI**.

---

##  Objectifs du Projet

- Automatiser le flux de donnÃ©es de Bronze â†’ Silver â†’ Gold
- CrÃ©er des vues Serverless dans Synapse pour l'analyse
- Construire un dashboard interactif avec Power BI

---

##  Technologies utilisÃ©es

| Outil | RÃ´le |
|------|------|
| **Azure Data Factory** | Orchestration des pipelines |
| **Azure Synapse Analytics** | Stockage Silver/Gold & requÃªtes serverless |
| **Azure Data Lake Storage Gen2** | Stockage des fichiers `.parquet` |
| **Databricks** | Nettoyage et transformation des donnÃ©es (notebooks) |
| **SQL Server + .bak** | Source des donnÃ©es AdventureWorks |
| **Power BI** | Visualisation des KPIs |

---

## ğŸ—‚ï¸ Arborescence du projet
Azure_data_pipeline/ â”œâ”€â”€ dashboard/ # Dashboard Power BI (.pbix) â”œâ”€â”€ data/ # DonnÃ©es brutes (.csv) â”œâ”€â”€ notebooks/ # Notebooks Databricks â”œâ”€â”€ pipelines/ # Pipelines exportÃ©s (ADF ou Synapse) â”œâ”€â”€ scripts/ # Scripts SQL et PowerShell â””â”€â”€ README.md

---

## ğŸ“¦ DonnÃ©es

- Fichier `.bak` de la base : `AdventureWorksLT2022.bak`
- Export CSV : via script `export_tables.ps1` dans `scripts/`

---

## â–¶ï¸ ExÃ©cution locale

1. Restaurer la base SQL depuis le `.bak`
2. Lancer `export_tables.ps1` pour gÃ©nÃ©rer les CSV
3. Charger les fichiers `.csv` dans Power BI

---

## ğŸ‘¤ Auteur

**Mohamed Aymen Halleb**  
Ã‰tudiant en ingÃ©nierie informatique Ã  l'EILCO  
[LinkedIn](https://www.linkedin.com/in/mohamed-aymen-halleb)

---

## â­ Remarques

- Ce projet est 100% local & open-source.
- Il peut Ãªtre dÃ©ployÃ© sur Azure ou exÃ©cutÃ© localement.
---
